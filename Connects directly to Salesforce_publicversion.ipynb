{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions to import data from Salesforce and build a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from datetime import datetime\n",
    "import beatbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_data_from_sf(sf_username, sf_password, sf_api_token):\n",
    "    #Returns a pandas dataframe with all opportunities\n",
    "    sf_creds=sf_password+sf_api_token\n",
    "    service = beatbox.PythonClient()  \n",
    "    service.login(sf_username, sf_creds)\n",
    "    query_result = service.query(\"SELECT Id, AccountId, Name, Description, Date_d_ouverture__c, Market_Competitors__c, Business_Model_Figures__c, Resume__c, Team__c, Round__c, Amount, CurrencyIsoCode, LeadSource, X1st_meeting__c FROM Opportunity WHERE Date_d_ouverture__c > 2009-01-01\") \n",
    "    records = query_result['records']\n",
    "    total_records = query_result['size']  # full size of results\n",
    "    query_locator = query_result['queryLocator']  # get the mystical queryLocator\n",
    "    # loop through, pulling the next 500 and appending it to your records dict\n",
    "    while query_result['done'] is False and len(records) < total_records:\n",
    "        query_result = service.queryMore(query_locator)\n",
    "        query_locator = query_result['queryLocator']  # get the updated queryLocator\n",
    "        records = records + query_result['records']\n",
    "    df = pd.DataFrame(records)\n",
    "    df.columns = ['AccountId', 'Amount_local_currency', 'BM_Figures', 'Currency', 'Open_Date', 'Description', 'Id', 'LeadSource', 'Market_Competitors', 'Name', 'Summary', 'Round', 'Team', '1stmeeting', 'type']\n",
    "    print \"Number of extracted opportunities:\"\n",
    "    print len(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_topicassignment_from_sf(sf_username, sf_password, sf_api_token):\n",
    "    sf_creds=sf_password+sf_api_token\n",
    "    service = beatbox.PythonClient()  \n",
    "    service.login(sf_username, sf_creds)\n",
    "    query_result_topics1 = service.query(\"SELECT TopicId, EntityId, IsDeleted FROM TopicAssignment WHERE  IsDeleted = False\") \n",
    "    records_topics1 = query_result_topics1['records']\n",
    "    total_records_topics1 = query_result_topics1['size']  # full size of results\n",
    "    query_locator_topics1 = query_result_topics1['queryLocator']  # get the mystical queryLocator\n",
    "    # loop through, pulling the next 500 and appending it to your records dict\n",
    "    while query_result_topics1['done'] is False and len(records_topics1) < total_records_topics1:\n",
    "        query_result_topics1 = service.queryMore(query_locator_topics1)\n",
    "        query_locator_topics1 = query_result_topics1['queryLocator']  # get the updated queryLocator\n",
    "        records_topics1 = records_topics1 + query_result_topics1['records']\n",
    "    TopicAssignment = pd.DataFrame(records_topics1)\n",
    "    TopicAssignment = TopicAssignment[['EntityId', 'TopicId', 'IsDeleted']]\n",
    "    return TopicAssignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_topicnames_from_sf(sf_username, sf_password, sf_api_token):\n",
    "    sf_creds=sf_password+sf_api_token\n",
    "    service = beatbox.PythonClient()  \n",
    "    service.login(sf_username, sf_creds)\n",
    "    query_result_topics2 = service.query(\"SELECT Id, Name FROM Topic\") \n",
    "    records_topics2 = query_result_topics2['records']\n",
    "    total_records_topics2 = query_result_topics2['size']  # full size of results\n",
    "    query_locator_topics2 = query_result_topics2['queryLocator']  # get the mystical queryLocator\n",
    "    # loop through, pulling the next 500 and appending it to your records dict\n",
    "    while query_result_topics2['done'] is False and len(records_topics2) < total_records_topics2:\n",
    "        query_result_topics2 = service.queryMore(query_locator_topics2)\n",
    "        query_locator_topics2 = query_result_topics2['queryLocator']  # get the updated queryLocator\n",
    "        records_topics2 = records_topics2 + query_result_topics2['records']\n",
    "    TopicNames = pd.DataFrame(records_topics2)\n",
    "    return TopicNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_topics_from_sf(sf_username, sf_password, sf_api_token):\n",
    "    TopicAssignment = extract_topicassignment_from_sf(sf_username, sf_password, sf_api_token)\n",
    "    TopicNames = extract_topicnames_from_sf(sf_username, sf_password, sf_api_token)\n",
    "    topics_df = pd.merge(TopicAssignment, TopicNames, how='inner', left_on='TopicId', right_on='Id')\n",
    "    topics_df.Name = topics_df.Name.map(lambda x : str(x).lower())\n",
    "    return topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import math\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Competitors processing\n",
    "def process_competitors_and_textvariables(df):\n",
    "    df['Competitors'] = 'No competitor'\n",
    "    for i in range(0,len(df.index)):\n",
    "        if pd.isnull(df.Market_Competitors[i]) == False:\n",
    "            sub_competitor_list = []\n",
    "            #Remove text between brackets\n",
    "            text = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", df.Market_Competitors[i])\n",
    "            #Remove multiple spaces\n",
    "            text = re.sub(' +',' ',text)\n",
    "            #Remove space before punctuation (\"Competitors :\" becomes \"Competitors:\")\n",
    "            text = re.sub(r'\\s([?.!\":](?:\\s|$))', r'\\1', text)\n",
    "            #Lower letters\n",
    "            text = text.lower()\n",
    "            if (\"competitors:\" in text) or (\"competitor:\" in text) or (\"competition:\" in text):\n",
    "                competitor_words_list = text.split(' ')\n",
    "                position = [competitor_words_list.index(j) for j in competitor_words_list if ('competitors:' in j) or ('competitor:' in j) or ('competition:' in j)] \n",
    "                #On rejoint tous les mots en un seul texte que l'on coupe ensuite au niveau des virgules ou des \":\" ou des \"+\"\n",
    "                sub_competitor_list = re.split(r'[,:+]+',''.join(competitor_words_list[position[0]+1:]))\n",
    "            df['Competitors'][i] = sub_competitor_list\n",
    "        else:\n",
    "            df['Competitors'][i] = list('')\n",
    "    #Process text variables\n",
    "    df.BM_Figures = df.BM_Figures.map(lambda x : str(x).lower())\n",
    "    df.Description = df.Description.map(lambda x : str(x).lower())\n",
    "    df.Summary = df.Summary.map(lambda x : str(x).lower())\n",
    "    df.Market_Competitors = df.Market_Competitors.map(lambda x : str(x).lower())\n",
    "    #Create Year variable\n",
    "    df['Year']= df['Open_Date'].map(lambda X: X.year)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Functions to check how many opportunities contain certain words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Find opportunities containing certain words (list_words_to_find) and without certain words (list_words_to_avoid)\n",
    "\n",
    "def findwordfrequency_withoutBM(df, topics_df, year_min, list_words_to_find, list_words_to_find_only_in_topics, list_words_to_avoid) :\n",
    "    sub_df = df[df.Year >= year_min]\n",
    "    #Search words in text\n",
    "    sub_df.Wholetext = sub_df.Summary + ' ' + sub_df.Description  + ' ' + sub_df.Market_Competitors\n",
    "    sub_df['check_text'] = sub_df.Wholetext.map(lambda text : 1 if any(x in text for x in list_words_to_find) else 0)\n",
    "    sub_df['check_text_bis'] = sub_df.Wholetext.map(lambda text : \"pb\" if any(x in text for x in list_words_to_avoid) else \"ok\")\n",
    "    sub_df.loc[sub_df['check_text_bis']==\"pb\", 'check_text'] = 0\n",
    "    #Search words in topics\n",
    "    sub_topics_df = topics_df[(topics_df.Name.isin(list_words_to_find) | topics_df.Name.isin(list_words_to_find_only_in_topics))]\n",
    "    list_id_withtopics = list(set(sub_topics_df.EntityId))\n",
    "    sub_df['check_topics'] = 0\n",
    "    sub_df.loc[sub_df.Id.isin(list_id_withtopics), 'check_topics'] = 1\n",
    "    list_id_withouttopics = list(set(topics_df[topics_df.Name.isin(list_words_to_avoid)].EntityId))\n",
    "    sub_df.loc[sub_df.Id.isin(list_id_withouttopics), 'check_topics'] = 0\n",
    "    #Combine both results\n",
    "    sub_df['check'] =  sub_df['check_text'] + sub_df['check_topics']\n",
    "    sub_df.loc[sub_df['check']>=1, 'check'] = 1\n",
    "    print \"Number of opportunities containing at least one of the words:\"\n",
    "    print len(sub_df[sub_df.check == 1])\n",
    "    return sub_df\n",
    "\n",
    "\n",
    "def findwordfrequency_withBM(df, topics_df, year_min, list_words_to_find, list_words_to_find_only_in_topics, list_words_to_avoid) :\n",
    "    sub_df = df[df.Year >= year_min]\n",
    "    #Search words in text\n",
    "    sub_df.Wholetext = sub_df.Summary + ' ' + sub_df.Description  + ' ' + sub_df.Market_Competitors + ' ' + sub_df.BM_Figures\n",
    "    sub_df['check_text'] = sub_df.Wholetext.map(lambda text : 1 if any(x in text for x in list_words_to_find) else 0)\n",
    "    sub_df['check_text_bis'] = sub_df.Wholetext.map(lambda text : \"pb\" if any(x in text for x in list_words_to_avoid) else \"ok\")\n",
    "    sub_df.loc[sub_df['check_text_bis']==\"pb\", 'check_text'] = 0\n",
    "    #Search words in topics\n",
    "    sub_topics_df = topics_df[(topics_df.Name.isin(list_words_to_find) | topics_df.Name.isin(list_words_to_find_only_in_topics))]\n",
    "    list_id_withtopics = list(set(sub_topics_df.EntityId))\n",
    "    sub_df['check_topics'] = 0\n",
    "    sub_df.loc[sub_df.Id.isin(list_id_withtopics), 'check_topics'] = 1\n",
    "    list_id_withouttopics = list(set(topics_df[topics_df.Name.isin(list_words_to_avoid)].EntityId))\n",
    "    sub_df.loc[sub_df.Id.isin(list_id_withouttopics), 'check_topics'] = 0\n",
    "    #Combine both results\n",
    "    sub_df['check'] =  sub_df['check_text'] + sub_df['check_topics']\n",
    "    sub_df.loc[sub_df['check']>=1, 'check'] = 1\n",
    "    print \"Number of opportunities containing at least one of the words:\"\n",
    "    print len(sub_df[sub_df.check == 1])\n",
    "    return sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_percentage_per_year(sub_df):\n",
    "    calc_check = pd.crosstab(index=sub_df[\"check\"], columns=sub_df[\"Year\"],margins=True)\n",
    "    list_years = list(set(sub_df[\"Year\"]))\n",
    "    list_years.sort()\n",
    "    list_years.append(\"rowtotal\")\n",
    "    calc_check.columns = list_years\n",
    "    calc_check.index= [\"False\", \"True\",\"coltotal\"]\n",
    "    new_calc_check=  (calc_check/calc_check.ix[\"coltotal\"])*100\n",
    "    return new_calc_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions to analyse competitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_corresp_table_competitors(df):\n",
    "    list_competitors = list(df.Competitors)\n",
    "    dataframe = pd.DataFrame(list_competitors)\n",
    "    dataframe['Id'] = pd.DataFrame(df.Id)\n",
    "    Opp_competitors = pd.melt(dataframe,id_vars='Id').sort('Id')\n",
    "    Opp_competitors = Opp_competitors[ pd.notnull(Opp_competitors['value'])] #Remove None\n",
    "    Opp_competitors = Opp_competitors[Opp_competitors['value'] != ''] #Remove empty cells\n",
    "    Opp_competitors = Opp_competitors[['Id','value']]\n",
    "    Opp_competitors.columns = ['Id', 'Competitor']\n",
    "    Opp_competitors = Opp_competitors.reset_index(drop = True)\n",
    "    #Add Open Date variable to the correspondence table\n",
    "    Opp_competitors = pd.merge(Opp_competitors, df,left_on='Id', right_on= 'Id')[['Id', 'Competitor', 'Open_Date']]\n",
    "    Opp_competitors[ pd.isnull(Opp_competitors['Open_Date'])] #Remove Opportunities without open dates\n",
    "    Opp_competitors['Year']= Opp_competitors['Open_Date'].map(lambda X: X.year) #Create an \"Open Year\" variable\n",
    "    return Opp_competitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to remove wrong competitors\n",
    "def remove_wrong_competitors(Opp_competitors, list_wrong_competitors):\n",
    "    for wrong_comp in list_wrong_competitors:\n",
    "        Opp_competitors = Opp_competitors[Opp_competitors.Competitor != wrong_comp]\n",
    "    return Opp_competitors\n",
    "\n",
    "#Function to change all competitor names containing a word to this word (ex: Google Gmail becomes Google)\n",
    "def clean_main_competitors(Opp_competitors, list_competitors_to_clean):\n",
    "    for comp in list_competitors_to_clean:\n",
    "        Opp_competitors.loc[Opp_competitors.Competitor.apply(lambda X: comp in X), 'Competitor'] = comp\n",
    "    return Opp_competitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Function to count the number of mentions of each competitor per Year (and the percentage of mentions per Year)\n",
    "def count_competitors_per_year(Opp_competitors):\n",
    "    count_competitors_date = pd.DataFrame(Opp_competitors.groupby(['Year','Competitor'])['Id'].nunique())\n",
    "    count_competitors_date = count_competitors_date.reset_index()\n",
    "    percentage_computation = count_competitors_date.groupby('Year').Id.apply(lambda x: 100*x/float(x.sum()))\n",
    "    count_competitors_date['pct'] = percentage_computation\n",
    "    count_competitors_date = count_competitors_date.sort_values( by = 'Year', ascending = True).reset_index(drop = True)     \n",
    "    return count_competitors_date\n",
    "\n",
    "#Function to add counts equal to 0 if the competitor is not mentioned at all\n",
    "def add_zeros(count_competitors_date):\n",
    "    list_displayed_competitors = list(set(count_competitors_date.Competitor))\n",
    "    list_years = list(set(count_competitors_date.Year))\n",
    "    list_years.sort()\n",
    "    #Put 0 in empty quarters / years\n",
    "    for competitor in list_displayed_competitors:\n",
    "        sub_df_comp = count_competitors_date[count_competitors_date.Competitor == competitor]\n",
    "        existing_dates = list(set(sub_df_comp.Year))\n",
    "        missing_dates = [x for x in list_years if x not in existing_dates]\n",
    "        if len( missing_dates) > 0:\n",
    "            to_append = pd.DataFrame(missing_dates)\n",
    "            to_append['Competitor'] = competitor\n",
    "            to_append['Id'] = 0\n",
    "            to_append['pct'] = 0\n",
    "            to_append.columns = ['Year', 'Competitor', 'Id', 'pct']\n",
    "            count_competitors_date = count_competitors_date.append(to_append)\n",
    "    \n",
    "    count_competitors_date = count_competitors_date.sort_values( by = 'Year', ascending = True).reset_index(drop = True)\n",
    "    return count_competitors_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extracted opportunities:\n",
      "8893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vtec-svtec1\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#################################################################################################################################\n",
    "sf_username = \"\"\n",
    "sf_password = \"\"\n",
    "sf_api_token = \"\"    \n",
    "#################################################################################################################################\n",
    "\n",
    "#Extract data from salesforce\n",
    "df = extract_data_from_sf(sf_username, sf_password, sf_api_token)\n",
    "topics_df =  extract_topics_from_sf(sf_username, sf_password, sf_api_token)\n",
    "#Process competitors\n",
    "df = process_competitors_and_textvariables(df)\n",
    "\n",
    "#Store the result as Pickle file\n",
    "\n",
    "#################################################################################################################################\n",
    "os.chdir('C:/Users/')\n",
    "#################################################################################################################################\n",
    "\n",
    "import pickle\n",
    "\n",
    "file_Name = \"df.p\"\n",
    "# open the file for writing\n",
    "fileObject = open(file_Name,'wb') \n",
    "\n",
    "# this writes the object a to the\n",
    "# file named 'testfile'\n",
    "pickle.dump(df,fileObject)   \n",
    "\n",
    "# here we close the fileObject\n",
    "fileObject.close()\n",
    "\n",
    "\n",
    "file_Name_2 = \"topics_df.p\"\n",
    "# open the file for writing\n",
    "fileObject_2 = open(file_Name_2,'wb') \n",
    "\n",
    "# this writes the object a to the\n",
    "# file named 'testfile'\n",
    "pickle.dump(topics_df,fileObject_2)   \n",
    "\n",
    "# here we close the fileObject\n",
    "fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################################################################################################################################\n",
    "os.chdir('C:/Users/')\n",
    "#################################################################################################################################\n",
    "\n",
    "#Load processed df\n",
    "import pickle\n",
    "file_Name = \"df.p\"\n",
    "# we open the file for reading\n",
    "fileObject = open(file_Name,'r')  \n",
    "# load the object from the file into var b\n",
    "df = pickle.load(fileObject)  \n",
    "\n",
    "file_Name_2 = \"topics_df.p\"\n",
    "# we open the file for reading\n",
    "fileObject_2 = open(file_Name_2,'r')  \n",
    "# load the object from the file into var b\n",
    "topics_df = pickle.load(fileObject_2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check which opportunities contain certain words and plot/export results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples:\n",
    "\n",
    "**E-commerce** : list_words_to_find  = [\"e-commerce\",\"ecommerce\",\"e commerce\",\"e-merchant\"]\n",
    "             list_words_to_avoid = [\"saas\", \"software\"]\n",
    "\n",
    "**Crowdfunding / P2P Lending** : ['crowdfunding', \"crowd funding\", \"p2p lending\", \"peer to peer lending\", \"peer-to-peer lending\", \"ptop lending\", \"crowdequity\", \"crowd equity\", \"money lending\"]\n",
    "\n",
    "**Insuretech** : list_words_to_find = ['insurance', 'insuretech', 'insurtech', 'insure tech', 'insurance tech']\n",
    "list_words_to_find_only_in_topics = []\n",
    "list_words_to_avoid = ['p2p boat renting platform', 'home exchange', 'neighborhood life', 'freelancers', 'bug bounty']\n",
    "\n",
    "**Blockchain** : ['blockchain', 'bitcoin']\n",
    "\n",
    "**Robo-Advisors** : ['robo-advisor', 'robo advisor', 'roboadvisor', 'investment management', 'wealth management', 'finance management', 'savings management', 'financial risk management']\n",
    "\n",
    "**AI / Big Data / Data Science** : list_words_to_find = [' ai ', 'artificial intelligence', 'machine learning', 'data science', 'predictive algorithms', 'predictive analysis', 'predictive analytics', 'data analytics', 'data mining', 'big data']\n",
    "\n",
    "**Food** : \n",
    "list_words_to_find = ['food', 'foodtech', 'food delivery', 'grocery delivery', 'meals']\n",
    "list_words_to_avoid = ['pets', 'animals']\n",
    "\n",
    "**SaaS** : list_words_to_find = ['saas']\n",
    "\n",
    "**Drones** : list_words_to_find = ['drone']\n",
    "\n",
    "**Cars** :  ['car sharing', 'carsharing', 'car rental', 'cars', 'vehicles', 'telematics', 'car selling', 'car pooling', 'carpooling']\n",
    "\n",
    "**Education** : list_words_to_find = ['e-learning', 'elearning', 'online course', 'online lesson', 'online class', 'online learning', 'mooc','edtech', \n",
    "                      'education platform', 'teachers', 'teaching', 'educational', 'educative', 'tutoring', 'corporate training', \n",
    "                      'corporate education', 'professional training', 'academic', 'education']\n",
    "list_words_to_find_only_in_topics = ['education']\n",
    "list_words_to_avoid = ['real estate']\n",
    "\n",
    "**Smart Home** : list_words_to_find = ['smart home', 'connected home','smarthome', 'smart light', 'connected light' 'connected thermostat', 'smart lock', 'smartlock', 'smart thermostat', 'smart door', 'connected door',\n",
    "                     'connected kitchen', 'connected house']\n",
    "\n",
    "**Virtual Assistant** :  list_words_to_find = ['virtual assistant', 'online assistant', 'chatbot', 'chat bot', 'personal assistant', ' bot ', 'chat assistant']\n",
    "\n",
    "**Agriculture**: list_words_to_find = ['agriculture', 'farming', 'farmer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Check which opportunities contain certain words in Summary or Description or Market Competitors\n",
    "#################################################################################################################################\n",
    "year_min = 2012\n",
    "list_words_to_find = ['crowd sourc', 'crowdsourc']\n",
    "list_words_to_find_only_in_topics = []\n",
    "list_words_to_avoid = []\n",
    "#################################################################################################################################\n",
    "\n",
    "#Without looking for the words in the 'Business Model / Figures' text\n",
    "sub_df = findwordfrequency_withoutBM(df, topics_df, year_min, list_words_to_find, list_words_to_find_only_in_topics, list_words_to_avoid)\n",
    "\n",
    "#Looking for the words everywhere\n",
    "#sub_df = findwordfrequency_withBM(df, year_min, list_words_to_find, list_words_to_avoid)\n",
    "\n",
    "############## CHECK IF THE SELECTED OPPORTUNITIES MAKE SENSE !!!!! ############################################################\n",
    "print 'Opportunities containing at least one of the word:'\n",
    "sub_df[sub_df.check == 1][['Name', 'Summary', 'Description', 'Competitors']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Export to check precisely\n",
    "sub_df[sub_df.check == 1][['Name', 'Summary', 'Description', 'Competitors']].to_csv('results.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>rowtotal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>99.566161</td>\n",
       "      <td>99.18284</td>\n",
       "      <td>99.072513</td>\n",
       "      <td>98.505338</td>\n",
       "      <td>99.523356</td>\n",
       "      <td>99.115683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.433839</td>\n",
       "      <td>0.81716</td>\n",
       "      <td>0.927487</td>\n",
       "      <td>1.494662</td>\n",
       "      <td>0.476644</td>\n",
       "      <td>0.884317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coltotal</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                2012       2013        2014        2015        2016  \\\n",
       "False      99.566161   99.18284   99.072513   98.505338   99.523356   \n",
       "True        0.433839    0.81716    0.927487    1.494662    0.476644   \n",
       "coltotal  100.000000  100.00000  100.000000  100.000000  100.000000   \n",
       "\n",
       "            rowtotal  \n",
       "False      99.115683  \n",
       "True        0.884317  \n",
       "coltotal  100.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compute percentages per year\n",
    "percentage_table = compute_percentage_per_year(sub_df)\n",
    "percentage_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Export results to csv\n",
    "percentage_table.to_csv('results.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file://C:\\\\Users\\\\vtec-svtec1\\\\Desktop\\\\Dealflow text mining\\\\temp-plot.html'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Plot results in Plotly\n",
    "######################################## CHOOSE YEARS TO KEEP ###################################################################\n",
    "percentage_table = percentage_table[[2012,2013,2014,2015, 2016]]\n",
    "#################################################################################################################################\n",
    "import plotly\n",
    "from plotly.graph_objs import Scatter\n",
    "from plotly.graph_objs import *\n",
    "\n",
    "plotly.offline.plot({\n",
    "    'data': [\n",
    "        Scatter(x=percentage_table.columns,\n",
    "                y=list(percentage_table.ix[1]),\n",
    "                text='',\n",
    "                marker=Marker(),\n",
    "                mode='lines+markers',\n",
    "                line=dict(shape='spline'))\n",
    "    ],\n",
    "    'layout': Layout(xaxis=XAxis(title='Time'), yaxis=YAxis(title='Percentage of yearly dealflow'), \n",
    "                     title = 'Evolution of the percentage of SaaS opportunities')\n",
    "}, show_link=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse competitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Build a dataframe containing 1 line for each Opportunity/Competitor pair\n",
    "Opp_competitors = build_corresp_table_competitors(df)\n",
    "\n",
    "################################################################################################################################\n",
    "list_wrong_competitors = ['us', 'etc', 'etc.', 'direct', 'indirect', 'traditionalplayers', '...', 'pureplayers', 'france', 'germany']\n",
    "#################################################################################################################################\n",
    "#Remove names identified as \"wrong competitors\"\n",
    "Opp_competitors = remove_wrong_competitors(Opp_competitors, list_wrong_competitors)\n",
    "\n",
    "\n",
    "#################################################################################################################################\n",
    "list_competitors_to_clean = ['facebook', 'google', 'youtube', 'oracle', 'microsoft', 'ibm', 'airbnb', 'groupon', 'linkedin', \n",
    "                             'ebay', 'apple', 'amazon', 'netflix', 'dropbox', 'leboncoin', 'salesforce', 'yelp', 'tripadvisor',\n",
    "                            'uber', 'paypal', 'skype', 'withings', 'meetic', 'tinder', 'foursquare', 'deezer', 'viber','expedia',\n",
    "                            'asos', 'farfetch', 'wix', 'prestashop','sony', 'twitter', 'instagram', 'pinterest', 'adobe', 'whatsapp',\n",
    "                            'snapchat', 'cisco', 'zynga', 'rovio', 'zalando', 'kickstarter', 'slack', 'parrot', 'wordpress','magento',\n",
    "                            'lafourchette', 'pagesjaunes', 'stripe']\n",
    "#################################################################################################################################\n",
    "############# /!\\ ALWAYS CHECK THE RESULT BEFORE ADDING ANY NEW NAME TO THE LIST (Some companies \n",
    "#             have names contained in other well known companies, especially companies with abbreviations in their names) ###########\n",
    "Opp_competitors = clean_main_competitors(Opp_competitors, list_competitors_to_clean)\n",
    "\n",
    "\n",
    "########################################################### CUSTOM CHANGES #########################################################\n",
    "Opp_competitors.Competitor[Opp_competitors.Competitor.apply(lambda X: 'ventepriv' in X)] = 'vente-privee'\n",
    "Opp_competitors.Competitor[Opp_competitors.Competitor.apply(lambda X: 'vente-priv' in X)] = 'vente-privee'\n",
    "Opp_competitors.Competitor[Opp_competitors.Competitor.apply(lambda X: 'vestiaire' in X)] = 'vestiairecollective'\n",
    "Opp_competitors.Competitor[Opp_competitors.Competitor.apply(lambda X: 'windows' in X)] = 'microsoft'\n",
    "Opp_competitors.Competitor[Opp_competitors.Competitor.apply(lambda X: 'itunes' in X)] = 'apple'\n",
    "\n",
    "\n",
    "Opp_competitors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Count mentions of each competitor per year (and the percentage among all mentions per year)\n",
    "count_competitors_date = count_competitors_per_year(Opp_competitors)\n",
    "\n",
    "##########################################################################################################################################\n",
    "year_min = 2013\n",
    "##########################################################################################################################################\n",
    "\n",
    "#Filter by year\n",
    "count_competitors_date = count_competitors_date[count_competitors_date.Year >= year_min]\n",
    "\n",
    "#Check which are the most cited competitors among all opportunities since year_min (See competitors cited more than nb_mentions_min times)\n",
    "nb_mentions_min = 5\n",
    "main_comp_df = pd.DataFrame(count_competitors_date.groupby('Competitor')['Id'].sum()).sort_values(by='Id', ascending = False).reset_index()\n",
    "main_comp_df = main_comp_df[main_comp_df.Id >= nb_mentions_min]\n",
    "#Display the most cited competitors among all opportunities since year_min\n",
    "main_comp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Choose competitors to display on the graph\n",
    "\n",
    "################################################################################################################################\n",
    "list_competitors_to_display = ['airbnb', 'booking.com', 'tripadvisor', 'yelp', 'expedia', 'couchsurfing']\n",
    "################################################################################################################################\n",
    "\n",
    "count_competitors_date_to_display = count_competitors_date[count_competitors_date.Competitor.isin(list_competitors_to_display)]\n",
    "count_competitors_date_to_display = add_zeros(count_competitors_date_to_display)\n",
    "count_competitors_date_to_display.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Export counts & pct for selected competitors to csv\n",
    "count_competitors_date_to_display.to_csv('results_competitors.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file://C:\\\\Users\\\\vtec-svtec1\\\\Desktop\\\\Dealflow text mining\\\\temp-plot.html'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Plot\n",
    "import plotly\n",
    "from plotly.graph_objs import Scatter\n",
    "from plotly.graph_objs import *\n",
    "\n",
    "plotly.offline.plot({\n",
    "    'data': [\n",
    "        Scatter(x=count_competitors_date_to_display[count_competitors_date_to_display.Competitor == competitor].Year,\n",
    "                y=count_competitors_date_to_display[count_competitors_date_to_display.Competitor == competitor].pct,\n",
    "                text='',\n",
    "                marker=Marker(),\n",
    "                mode='lines+markers',\n",
    "                line=dict(shape='spline'),\n",
    "                name=competitor) for competitor in list_competitors_to_display\n",
    "    ],\n",
    "    'layout': Layout(xaxis=XAxis(title='Time'), yaxis=YAxis(title='Percentage of yearly dealflow'), title = 'Startups main competitors')\n",
    "}, show_link=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
