{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions to import data from Salesforce and build a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from datetime import datetime\n",
    "import beatbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_data_from_sf(sf_username, sf_password, sf_api_token):\n",
    "    #Returns a pandas dataframe with all opportunities\n",
    "    sf_creds=sf_password+sf_api_token\n",
    "    service = beatbox.PythonClient()  \n",
    "    service.login(sf_username, sf_creds)\n",
    "    query_result = service.query(\"SELECT Id, AccountId, Name, Description, Date_d_ouverture__c, Market_Competitors__c, Business_Model_Figures__c, Resume__c, Team__c, Round__c, Amount, CurrencyIsoCode, LeadSource, X1st_meeting__c FROM Opportunity WHERE Date_d_ouverture__c > 2009-01-01\") \n",
    "    records = query_result['records']\n",
    "    total_records = query_result['size']  # full size of results\n",
    "    query_locator = query_result['queryLocator']  # get the mystical queryLocator\n",
    "    # loop through, pulling the next 500 and appending it to your records dict\n",
    "    while query_result['done'] is False and len(records) < total_records:\n",
    "        query_result = service.queryMore(query_locator)\n",
    "        query_locator = query_result['queryLocator']  # get the updated queryLocator\n",
    "        records = records + query_result['records']\n",
    "    df = pd.DataFrame(records)\n",
    "    df.columns = ['AccountId', 'Amount_local_currency', 'BM_Figures', 'Currency', 'Open_Date', 'Description', 'Id', 'LeadSource', 'Market_Competitors', 'Name', 'Summary', 'Round', 'Team', '1stmeeting', 'type']\n",
    "    print \"Number of extracted opportunities:\"\n",
    "    print len(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_topicassignment_from_sf(sf_username, sf_password, sf_api_token):\n",
    "    sf_creds=sf_password+sf_api_token\n",
    "    service = beatbox.PythonClient()  \n",
    "    service.login(sf_username, sf_creds)\n",
    "    query_result_topics1 = service.query(\"SELECT TopicId, EntityId, IsDeleted FROM TopicAssignment WHERE  IsDeleted = False\") \n",
    "    records_topics1 = query_result_topics1['records']\n",
    "    total_records_topics1 = query_result_topics1['size']  # full size of results\n",
    "    query_locator_topics1 = query_result_topics1['queryLocator']  # get the mystical queryLocator\n",
    "    # loop through, pulling the next 500 and appending it to your records dict\n",
    "    while query_result_topics1['done'] is False and len(records_topics1) < total_records_topics1:\n",
    "        query_result_topics1 = service.queryMore(query_locator_topics1)\n",
    "        query_locator_topics1 = query_result_topics1['queryLocator']  # get the updated queryLocator\n",
    "        records_topics1 = records_topics1 + query_result_topics1['records']\n",
    "    TopicAssignment = pd.DataFrame(records_topics1)\n",
    "    TopicAssignment = TopicAssignment[['EntityId', 'TopicId', 'IsDeleted']]\n",
    "    return TopicAssignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_topicnames_from_sf(sf_username, sf_password, sf_api_token):\n",
    "    sf_creds=sf_password+sf_api_token\n",
    "    service = beatbox.PythonClient()  \n",
    "    service.login(sf_username, sf_creds)\n",
    "    query_result_topics2 = service.query(\"SELECT Id, Name FROM Topic\") \n",
    "    records_topics2 = query_result_topics2['records']\n",
    "    total_records_topics2 = query_result_topics2['size']  # full size of results\n",
    "    query_locator_topics2 = query_result_topics2['queryLocator']  # get the mystical queryLocator\n",
    "    # loop through, pulling the next 500 and appending it to your records dict\n",
    "    while query_result_topics2['done'] is False and len(records_topics2) < total_records_topics2:\n",
    "        query_result_topics2 = service.queryMore(query_locator_topics2)\n",
    "        query_locator_topics2 = query_result_topics2['queryLocator']  # get the updated queryLocator\n",
    "        records_topics2 = records_topics2 + query_result_topics2['records']\n",
    "    TopicNames = pd.DataFrame(records_topics2)\n",
    "    return TopicNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_topics_from_sf(sf_username, sf_password, sf_api_token):\n",
    "    TopicAssignment = extract_topicassignment_from_sf(sf_username, sf_password, sf_api_token)\n",
    "    TopicNames = extract_topicnames_from_sf(sf_username, sf_password, sf_api_token)\n",
    "    topics_df = pd.merge(TopicAssignment, TopicNames, how='inner', left_on='TopicId', right_on='Id')\n",
    "    topics_df.Name = topics_df.Name.map(lambda x : str(x).lower())\n",
    "    return topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import math\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Competitors processing\n",
    "def process_competitors_and_textvariables(df):\n",
    "    df['Competitors'] = 'No competitor'\n",
    "    for i in range(0,len(df.index)):\n",
    "        if pd.isnull(df.Market_Competitors[i]) == False:\n",
    "            sub_competitor_list = []\n",
    "            #Remove text between brackets\n",
    "            text = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", df.Market_Competitors[i])\n",
    "            #Remove multiple spaces\n",
    "            text = re.sub(' +',' ',text)\n",
    "            #Remove space before punctuation (\"Competitors :\" becomes \"Competitors:\")\n",
    "            text = re.sub(r'\\s([?.!\":](?:\\s|$))', r'\\1', text)\n",
    "            #Lower letters\n",
    "            text = text.lower()\n",
    "            if (\"competitors:\" in text) or (\"competitor:\" in text) or (\"competition:\" in text):\n",
    "                competitor_words_list = text.split(' ')\n",
    "                position = [competitor_words_list.index(j) for j in competitor_words_list if ('competitors:' in j) or ('competitor:' in j) or ('competition:' in j)] \n",
    "                #On rejoint tous les mots en un seul texte que l'on coupe ensuite au niveau des virgules ou des \":\" ou des \"+\"\n",
    "                sub_competitor_list = re.split(r'[,:+]+',''.join(competitor_words_list[position[0]+1:]))\n",
    "            df['Competitors'][i] = sub_competitor_list\n",
    "        else:\n",
    "            df['Competitors'][i] = list('')\n",
    "    #Process text variables\n",
    "    df.BM_Figures = df.BM_Figures.map(lambda x : str(x).lower())\n",
    "    df.Description = df.Description.map(lambda x : str(x).lower())\n",
    "    df.Summary = df.Summary.map(lambda x : str(x).lower())\n",
    "    df.Market_Competitors = df.Market_Competitors.map(lambda x : str(x).lower())\n",
    "    #Create Year variable\n",
    "    df['Year']= df['Open_Date'].map(lambda X: X.year)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Functions to check how many opportunities contain certain words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Find opportunities containing certain words (list_words_to_find) and without certain words (list_words_to_avoid)\n",
    "\n",
    "def findwordfrequency_withoutBM(df, topics_df, year_min, list_words_to_find, list_words_to_find_only_in_topics, list_words_to_avoid) :\n",
    "    sub_df = df[df.Year >= year_min]\n",
    "    #Search words in text\n",
    "    sub_df.Wholetext = sub_df.Summary + ' ' + sub_df.Description  + ' ' + sub_df.Market_Competitors\n",
    "    sub_df['check_text'] = sub_df.Wholetext.map(lambda text : 1 if any(x in text for x in list_words_to_find) else 0)\n",
    "    sub_df['check_text_bis'] = sub_df.Wholetext.map(lambda text : \"pb\" if any(x in text for x in list_words_to_avoid) else \"ok\")\n",
    "    sub_df.loc[sub_df['check_text_bis']==\"pb\", 'check_text'] = 0\n",
    "    #Search words in topics\n",
    "    sub_topics_df = topics_df[(topics_df.Name.isin(list_words_to_find) | topics_df.Name.isin(list_words_to_find_only_in_topics))]\n",
    "    list_id_withtopics = list(set(sub_topics_df.EntityId))\n",
    "    sub_df['check_topics'] = 0\n",
    "    sub_df.loc[sub_df.Id.isin(list_id_withtopics), 'check_topics'] = 1\n",
    "    list_id_withouttopics = list(set(topics_df[topics_df.Name.isin(list_words_to_avoid)].EntityId))\n",
    "    sub_df.loc[sub_df.Id.isin(list_id_withouttopics), 'check_topics'] = 0\n",
    "    #Combine both results\n",
    "    sub_df['check'] =  sub_df['check_text'] + sub_df['check_topics']\n",
    "    sub_df.loc[sub_df['check']>=1, 'check'] = 1\n",
    "    print \"Number of opportunities containing at least one of the words:\"\n",
    "    print len(sub_df[sub_df.check == 1])\n",
    "    return sub_df\n",
    "\n",
    "\n",
    "def findwordfrequency_withBM(df, topics_df, year_min, list_words_to_find, list_words_to_find_only_in_topics, list_words_to_avoid) :\n",
    "    sub_df = df[df.Year >= year_min]\n",
    "    #Search words in text\n",
    "    sub_df.Wholetext = sub_df.Summary + ' ' + sub_df.Description  + ' ' + sub_df.Market_Competitors + ' ' + sub_df.BM_Figures\n",
    "    sub_df['check_text'] = sub_df.Wholetext.map(lambda text : 1 if any(x in text for x in list_words_to_find) else 0)\n",
    "    sub_df['check_text_bis'] = sub_df.Wholetext.map(lambda text : \"pb\" if any(x in text for x in list_words_to_avoid) else \"ok\")\n",
    "    sub_df.loc[sub_df['check_text_bis']==\"pb\", 'check_text'] = 0\n",
    "    #Search words in topics\n",
    "    sub_topics_df = topics_df[(topics_df.Name.isin(list_words_to_find) | topics_df.Name.isin(list_words_to_find_only_in_topics))]\n",
    "    list_id_withtopics = list(set(sub_topics_df.EntityId))\n",
    "    sub_df['check_topics'] = 0\n",
    "    sub_df.loc[sub_df.Id.isin(list_id_withtopics), 'check_topics'] = 1\n",
    "    list_id_withouttopics = list(set(topics_df[topics_df.Name.isin(list_words_to_avoid)].EntityId))\n",
    "    sub_df.loc[sub_df.Id.isin(list_id_withouttopics), 'check_topics'] = 0\n",
    "    #Combine both results\n",
    "    sub_df['check'] =  sub_df['check_text'] + sub_df['check_topics']\n",
    "    sub_df.loc[sub_df['check']>=1, 'check'] = 1\n",
    "    print \"Number of opportunities containing at least one of the words:\"\n",
    "    print len(sub_df[sub_df.check == 1])\n",
    "    return sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_percentage_per_year(sub_df):\n",
    "    calc_check = pd.crosstab(index=sub_df[\"check\"], columns=sub_df[\"Year\"],margins=True)\n",
    "    list_years = list(set(sub_df[\"Year\"]))\n",
    "    list_years.sort()\n",
    "    list_years.append(\"rowtotal\")\n",
    "    calc_check.columns = list_years\n",
    "    calc_check.index= [\"False\", \"True\",\"coltotal\"]\n",
    "    new_calc_check=  (calc_check/calc_check.ix[\"coltotal\"])*100\n",
    "    return new_calc_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions to analyse competitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_corresp_table_competitors(df):\n",
    "    list_competitors = list(df.Competitors)\n",
    "    dataframe = pd.DataFrame(list_competitors)\n",
    "    dataframe['Id'] = pd.DataFrame(df.Id)\n",
    "    Opp_competitors = pd.melt(dataframe,id_vars='Id').sort('Id')\n",
    "    Opp_competitors = Opp_competitors[ pd.notnull(Opp_competitors['value'])] #Remove None\n",
    "    Opp_competitors = Opp_competitors[Opp_competitors['value'] != ''] #Remove empty cells\n",
    "    Opp_competitors = Opp_competitors[['Id','value']]\n",
    "    Opp_competitors.columns = ['Id', 'Competitor']\n",
    "    Opp_competitors = Opp_competitors.reset_index(drop = True)\n",
    "    #Add Open Date variable to the correspondence table\n",
    "    Opp_competitors = pd.merge(Opp_competitors, df,left_on='Id', right_on= 'Id')[['Id', 'Competitor', 'Open_Date']]\n",
    "    Opp_competitors[ pd.isnull(Opp_competitors['Open_Date'])] #Remove Opportunities without open dates\n",
    "    Opp_competitors['Year']= Opp_competitors['Open_Date'].map(lambda X: X.year) #Create an \"Open Year\" variable\n",
    "    return Opp_competitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to remove wrong competitors\n",
    "def remove_wrong_competitors(Opp_competitors, list_wrong_competitors):\n",
    "    for wrong_comp in list_wrong_competitors:\n",
    "        Opp_competitors = Opp_competitors[Opp_competitors.Competitor != wrong_comp]\n",
    "    return Opp_competitors\n",
    "\n",
    "#Function to change all competitor names containing a word to this word (ex: Google Gmail becomes Google)\n",
    "def clean_main_competitors(Opp_competitors, list_competitors_to_clean):\n",
    "    for comp in list_competitors_to_clean:\n",
    "        Opp_competitors.loc[Opp_competitors.Competitor.apply(lambda X: comp in X), 'Competitor'] = comp\n",
    "    return Opp_competitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Function to count the number of mentions of each competitor per Year (and the percentage of mentions per Year)\n",
    "def count_competitors_per_year(Opp_competitors):\n",
    "    count_competitors_date = pd.DataFrame(Opp_competitors.groupby(['Year','Competitor'])['Id'].nunique())\n",
    "    count_competitors_date = count_competitors_date.reset_index()\n",
    "    percentage_computation = count_competitors_date.groupby('Year').Id.apply(lambda x: 100*x/float(x.sum()))\n",
    "    count_competitors_date['pct'] = percentage_computation\n",
    "    count_competitors_date = count_competitors_date.sort_values( by = 'Year', ascending = True).reset_index(drop = True)     \n",
    "    return count_competitors_date\n",
    "\n",
    "#Function to add counts equal to 0 if the competitor is not mentioned at all\n",
    "def add_zeros(count_competitors_date):\n",
    "    list_displayed_competitors = list(set(count_competitors_date.Competitor))\n",
    "    list_years = list(set(count_competitors_date.Year))\n",
    "    list_years.sort()\n",
    "    #Put 0 in empty quarters / years\n",
    "    for competitor in list_displayed_competitors:\n",
    "        sub_df_comp = count_competitors_date[count_competitors_date.Competitor == competitor]\n",
    "        existing_dates = list(set(sub_df_comp.Year))\n",
    "        missing_dates = [x for x in list_years if x not in existing_dates]\n",
    "        if len( missing_dates) > 0:\n",
    "            to_append = pd.DataFrame(missing_dates)\n",
    "            to_append['Competitor'] = competitor\n",
    "            to_append['Id'] = 0\n",
    "            to_append['pct'] = 0\n",
    "            to_append.columns = ['Year', 'Competitor', 'Id', 'pct']\n",
    "            count_competitors_date = count_competitors_date.append(to_append)\n",
    "    \n",
    "    count_competitors_date = count_competitors_date.sort_values( by = 'Year', ascending = True).reset_index(drop = True)\n",
    "    return count_competitors_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extracted opportunities:\n",
      "8893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vtec-svtec1\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#################################################################################################################################\n",
    "sf_username = \"romain.minaud@ventechvc.com\"\n",
    "sf_password = \"vtdf100cool\"\n",
    "sf_api_token = \"jW3v8IHV573VSQxlNDRHWmkU\"    \n",
    "#################################################################################################################################\n",
    "\n",
    "#Extract data from salesforce\n",
    "df = extract_data_from_sf(sf_username, sf_password, sf_api_token)\n",
    "topics_df =  extract_topics_from_sf(sf_username, sf_password, sf_api_token)\n",
    "#Process competitors\n",
    "df = process_competitors_and_textvariables(df)\n",
    "\n",
    "#Store the result as Pickle file\n",
    "\n",
    "#################################################################################################################################\n",
    "os.chdir('C:/Users/vtec-svtec1/Desktop/Dealflow text mining/')\n",
    "#################################################################################################################################\n",
    "\n",
    "import pickle\n",
    "\n",
    "file_Name = \"df.p\"\n",
    "# open the file for writing\n",
    "fileObject = open(file_Name,'wb') \n",
    "\n",
    "# this writes the object a to the\n",
    "# file named 'testfile'\n",
    "pickle.dump(df,fileObject)   \n",
    "\n",
    "# here we close the fileObject\n",
    "fileObject.close()\n",
    "\n",
    "\n",
    "file_Name_2 = \"topics_df.p\"\n",
    "# open the file for writing\n",
    "fileObject_2 = open(file_Name_2,'wb') \n",
    "\n",
    "# this writes the object a to the\n",
    "# file named 'testfile'\n",
    "pickle.dump(topics_df,fileObject_2)   \n",
    "\n",
    "# here we close the fileObject\n",
    "fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AccountId</th>\n",
       "      <th>Amount_local_currency</th>\n",
       "      <th>BM_Figures</th>\n",
       "      <th>Currency</th>\n",
       "      <th>Open_Date</th>\n",
       "      <th>Description</th>\n",
       "      <th>Id</th>\n",
       "      <th>LeadSource</th>\n",
       "      <th>Market_Competitors</th>\n",
       "      <th>Name</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Round</th>\n",
       "      <th>Team</th>\n",
       "      <th>1stmeeting</th>\n",
       "      <th>type</th>\n",
       "      <th>Competitors</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001b0000003bv0wAAA</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td></td>\n",
       "      <td>USD</td>\n",
       "      <td>2010-02-11</td>\n",
       "      <td>construction of a regional fibre-optic network...</td>\n",
       "      <td>006b00000023vJZAAY</td>\n",
       "      <td>Direct</td>\n",
       "      <td></td>\n",
       "      <td>Projet Réseau Fibre Optique _1</td>\n",
       "      <td>fibre-optic network construction</td>\n",
       "      <td>A</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>Opportunity</td>\n",
       "      <td>[]</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001b0000003btQRAAY</td>\n",
       "      <td>5000000.0</td>\n",
       "      <td></td>\n",
       "      <td>EUR</td>\n",
       "      <td>2009-03-03</td>\n",
       "      <td>provider of on-demand enterprise performance m...</td>\n",
       "      <td>006b00000023vQoAAI</td>\n",
       "      <td>Financial Advisor</td>\n",
       "      <td></td>\n",
       "      <td>Corporater _1</td>\n",
       "      <td></td>\n",
       "      <td>B</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>Opportunity</td>\n",
       "      <td>[]</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AccountId  Amount_local_currency BM_Figures Currency   Open_Date  \\\n",
       "0  001b0000003bv0wAAA             10000000.0                 USD  2010-02-11   \n",
       "1  001b0000003btQRAAY              5000000.0                 EUR  2009-03-03   \n",
       "\n",
       "                                         Description                  Id  \\\n",
       "0  construction of a regional fibre-optic network...  006b00000023vJZAAY   \n",
       "1  provider of on-demand enterprise performance m...  006b00000023vQoAAI   \n",
       "\n",
       "          LeadSource Market_Competitors                            Name  \\\n",
       "0             Direct                     Projet Réseau Fibre Optique _1   \n",
       "1  Financial Advisor                                      Corporater _1   \n",
       "\n",
       "                            Summary Round Team 1stmeeting         type  \\\n",
       "0  fibre-optic network construction     A           False  Opportunity   \n",
       "1                                       B           False  Opportunity   \n",
       "\n",
       "  Competitors  Year  \n",
       "0          []  2010  \n",
       "1          []  2009  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################################################################################################################################\n",
    "os.chdir('C:/Users/vtec-svtec1/Desktop/Dealflow text mining/')\n",
    "#################################################################################################################################\n",
    "\n",
    "#Load processed df\n",
    "import pickle\n",
    "file_Name = \"df.p\"\n",
    "# we open the file for reading\n",
    "fileObject = open(file_Name,'r')  \n",
    "# load the object from the file into var b\n",
    "df = pickle.load(fileObject)  \n",
    "\n",
    "file_Name_2 = \"topics_df.p\"\n",
    "# we open the file for reading\n",
    "fileObject_2 = open(file_Name_2,'r')  \n",
    "# load the object from the file into var b\n",
    "topics_df = pickle.load(fileObject_2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check which opportunities contain certain words and plot/export results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples:\n",
    "\n",
    "**E-commerce** : list_words_to_find  = [\"e-commerce\",\"ecommerce\",\"e commerce\",\"e-merchant\"]\n",
    "             list_words_to_avoid = [\"saas\", \"software\"]\n",
    "\n",
    "**Crowdfunding / P2P Lending** : ['crowdfunding', \"crowd funding\", \"p2p lending\", \"peer to peer lending\", \"peer-to-peer lending\", \"ptop lending\", \"crowdequity\", \"crowd equity\", \"money lending\"]\n",
    "\n",
    "**Insuretech** : list_words_to_find = ['insurance', 'insuretech', 'insurtech', 'insure tech', 'insurance tech']\n",
    "list_words_to_find_only_in_topics = []\n",
    "list_words_to_avoid = ['p2p boat renting platform', 'home exchange', 'neighborhood life', 'freelancers', 'bug bounty']\n",
    "\n",
    "**Blockchain** : ['blockchain', 'bitcoin']\n",
    "\n",
    "**Robo-Advisors** : ['robo-advisor', 'robo advisor', 'roboadvisor', 'investment management', 'wealth management', 'finance management', 'savings management', 'financial risk management']\n",
    "\n",
    "**AI / Big Data / Data Science** : list_words_to_find = [' ai ', 'artificial intelligence', 'machine learning', 'data science', 'predictive algorithms', 'predictive analysis', 'predictive analytics', 'data analytics', 'data mining', 'big data']\n",
    "\n",
    "**Food** : \n",
    "list_words_to_find = ['food', 'foodtech', 'food delivery', 'grocery delivery', 'meals']\n",
    "list_words_to_avoid = ['pets', 'animals']\n",
    "\n",
    "**SaaS** : list_words_to_find = ['saas']\n",
    "\n",
    "**Drones** : list_words_to_find = ['drone']\n",
    "\n",
    "**Cars** :  ['car sharing', 'carsharing', 'car rental', 'cars', 'vehicles', 'telematics', 'car selling', 'car pooling', 'carpooling']\n",
    "\n",
    "**Education** : list_words_to_find = ['e-learning', 'elearning', 'online course', 'online lesson', 'online class', 'online learning', 'mooc','edtech', \n",
    "                      'education platform', 'teachers', 'teaching', 'educational', 'educative', 'tutoring', 'corporate training', \n",
    "                      'corporate education', 'professional training', 'academic', 'education']\n",
    "list_words_to_find_only_in_topics = ['education']\n",
    "list_words_to_avoid = ['real estate']\n",
    "\n",
    "**Smart Home** : list_words_to_find = ['smart home', 'connected home','smarthome', 'smart light', 'connected light' 'connected thermostat', 'smart lock', 'smartlock', 'smart thermostat', 'smart door', 'connected door',\n",
    "                     'connected kitchen', 'connected house']\n",
    "\n",
    "**Virtual Assistant** :  list_words_to_find = ['virtual assistant', 'online assistant', 'chatbot', 'chat bot', 'personal assistant', ' bot ', 'chat assistant']\n",
    "\n",
    "**Agriculture**: list_words_to_find = ['agriculture', 'farming', 'farmer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vtec-svtec1\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\vtec-svtec1\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\vtec-svtec1\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of opportunities containing at least one of the words:\n",
      "49\n",
      "Opportunities containing at least one of the word:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vtec-svtec1\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Description</th>\n",
       "      <th>Competitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>Web of Trust _1</td>\n",
       "      <td>online safety through crowdsourcing</td>\n",
       "      <td>source's name : inventure (slush). founded in ...</td>\n",
       "      <td>[avast, symantec, mcafee, kingsoft, avg, avira...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286</th>\n",
       "      <td>Parko_1</td>\n",
       "      <td>crowdsourcing mobile app to find a parking spot</td>\n",
       "      <td>based in israel, crowdsourced data about peopl...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2311</th>\n",
       "      <td>Mon Code Juridique_1</td>\n",
       "      <td>cross-platform app for legal code</td>\n",
       "      <td>founded in 2012 and based in paris, mon code j...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2333</th>\n",
       "      <td>Tazza_1</td>\n",
       "      <td>online search engine of offline products</td>\n",
       "      <td>tazza is a search engine of offline products b...</td>\n",
       "      <td>[googlemaps, yelps, pinterest, facebook, fours...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2374</th>\n",
       "      <td>Darjeelin_2</td>\n",
       "      <td>crowdsourced travel agency</td>\n",
       "      <td>launched a year ago\\nusers can ask to the comm...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417</th>\n",
       "      <td>Ideator Crowd_1</td>\n",
       "      <td>ideas crowdsourcing platform via gamification</td>\n",
       "      <td>founded in turkey in 2013\\nideator crowd is a ...</td>\n",
       "      <td>[spigit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2538</th>\n",
       "      <td>Project 1411_1</td>\n",
       "      <td>weather crowdsourcing</td>\n",
       "      <td>project 1411 develops a weather crowdsourcing ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2743</th>\n",
       "      <td>Geniuzz_1</td>\n",
       "      <td>crowsourcing marketplace for professional onli...</td>\n",
       "      <td>founded in 2011.spain. crowdsourcing marketpla...</td>\n",
       "      <td>[freelancer.com, fiverr, nubelo, twago, bizzby]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2769</th>\n",
       "      <td>Mobbr_1</td>\n",
       "      <td>crowdsourced labor platform</td>\n",
       "      <td>2012. delft (netherlands). launch in october 2...</td>\n",
       "      <td>[clickworker, crowdflower, odesk, elance, agen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2903</th>\n",
       "      <td>MycrowdQA_1</td>\n",
       "      <td>crowsourcing and freelancing qa plattform (bug...</td>\n",
       "      <td>founded in 03/2013 launched in q42014 in the v...</td>\n",
       "      <td>[applause/utest, usertesting, crowdcurity, bug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4293</th>\n",
       "      <td>Mobeye_1</td>\n",
       "      <td>mobile app that crowdsources local and realtim...</td>\n",
       "      <td>founded in 2013 in france, mobeye is an app th...</td>\n",
       "      <td>[clickandwalk, bpeekandlocaleyes.us, quri, gig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4313</th>\n",
       "      <td>Be-novative_1</td>\n",
       "      <td>software supporting open enterprise innovation...</td>\n",
       "      <td>hungary based, the company provides a saas pla...</td>\n",
       "      <td>[spigit, chaordix, nosco, brigthidea, hype, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4856</th>\n",
       "      <td>BeMyEye_1</td>\n",
       "      <td>mobile app service for crowdsourcing store checks</td>\n",
       "      <td>bemyeye can provide images and data from any l...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4870</th>\n",
       "      <td>CrowdSystems_1</td>\n",
       "      <td>russian based mobile app service for crowdsour...</td>\n",
       "      <td>launched in q4 2012, crowdsystems created an s...</td>\n",
       "      <td>[gigwalk, fieldagent, easyshift, streetspotr]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4885</th>\n",
       "      <td>Scoopshot_1</td>\n",
       "      <td>crowdsource / competition for pictures/videos ...</td>\n",
       "      <td>founded in april 2010, scoopshot  is a crowdso...</td>\n",
       "      <td>[cnnireport, celljournalist, geltyimages, flic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4900</th>\n",
       "      <td>Qwyk_1</td>\n",
       "      <td>crowdsourced same day delivery service</td>\n",
       "      <td>launch in q3 2013, qwyk develops a crowdsource...</td>\n",
       "      <td>[nodirect, indirect, tiramizoo, shutl, deliv.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5228</th>\n",
       "      <td>WhereToGet_1</td>\n",
       "      <td>shazam for shopping</td>\n",
       "      <td>wheretoget is a 'shazam for shopping' : mobile...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5305</th>\n",
       "      <td>OdinOtvet _1</td>\n",
       "      <td>russian crowdsourcing platform for knowledge a...</td>\n",
       "      <td>combine best features of social network and wi...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5489</th>\n",
       "      <td>Sportcloud_1</td>\n",
       "      <td>performance sharing app</td>\n",
       "      <td>prelaunch in france. (prebeta phase) the compa...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5620</th>\n",
       "      <td>Tcheck’it_1</td>\n",
       "      <td>crowdsourcing marketing checking</td>\n",
       "      <td>launch in 05/2014 in france. there solution is...</td>\n",
       "      <td>[localeyesclickandwalk, roamler, bpeekandmobey...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5673</th>\n",
       "      <td>welovewords _1</td>\n",
       "      <td>communautary platform for authors</td>\n",
       "      <td>crowdsourcing ( brands want brandnames, mottos...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5786</th>\n",
       "      <td>Wezzoo_1</td>\n",
       "      <td>crowdsourced weather service along with social...</td>\n",
       "      <td>founded in 2012\\n2targets: b2c, b2b (white lab...</td>\n",
       "      <td>[weddar, metwit, skymotion, weathermob]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5800</th>\n",
       "      <td>Agorize_1</td>\n",
       "      <td>crowdsourcing platform for companies competitions</td>\n",
       "      <td>founded in 2012 in france, agorize is a platfo...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5813</th>\n",
       "      <td>Recommend_2</td>\n",
       "      <td>crowdsourcing recommendation social network</td>\n",
       "      <td>founded in france 2013\\nrecommend is an online...</td>\n",
       "      <td>[facebook, foursquaretwitter, pinterest, yelp,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6346</th>\n",
       "      <td>Yoobic_1</td>\n",
       "      <td>crowdsourced store check</td>\n",
       "      <td>yoobic is a crowdsourcing mobile app that allo...</td>\n",
       "      <td>[stayinfront, zenput, traxretail]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6381</th>\n",
       "      <td>Front Row Society_1</td>\n",
       "      <td>crowd sourced fashion label</td>\n",
       "      <td>launched in germany. high quality women access...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>BeMyEye_2</td>\n",
       "      <td>on-demand field audits via mobile crowdsourcing</td>\n",
       "      <td>bemyeye can provide images and data from any l...</td>\n",
       "      <td>[streetspotr, roamler, appjobber, clicandwalk,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6553</th>\n",
       "      <td>Evergig _3</td>\n",
       "      <td>crowdsourced video for concert.</td>\n",
       "      <td>founded in 06/2012 in france. the company uses...</td>\n",
       "      <td>[vevo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6668</th>\n",
       "      <td>Good Morning Design_1</td>\n",
       "      <td>marketplace for selling, renting and crowdsour...</td>\n",
       "      <td>3 core activities : selling second-hand furnit...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6682</th>\n",
       "      <td>MycrowdQA_2</td>\n",
       "      <td>crowsourcing and freelancing qa plattform (bug...</td>\n",
       "      <td>founded in 03/2013 launched in q42014 in the v...</td>\n",
       "      <td>[applause/utest, usertesting, crowdcurity, bug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6717</th>\n",
       "      <td>Testbirds_1</td>\n",
       "      <td>crowdtesting company</td>\n",
       "      <td>launched in germany in 2011. uses crowdsourcin...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7051</th>\n",
       "      <td>Evergig _2</td>\n",
       "      <td>crowdsourced video for concert.</td>\n",
       "      <td>founded in 06/2012 in france. the company uses...</td>\n",
       "      <td>[vevo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7095</th>\n",
       "      <td>Foule Factory_1</td>\n",
       "      <td>crowdsourcing marketplace specialized in micro...</td>\n",
       "      <td>founded in june 2014. foule factory offers the...</td>\n",
       "      <td>[amazonmechanicalturk, crowdflowerclickworker,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7300</th>\n",
       "      <td>Immodeo_1</td>\n",
       "      <td>automated realestate agency</td>\n",
       "      <td>prelaunch in france. immodeo ptop real estate ...</td>\n",
       "      <td>[orpi, fnaim, foncia, proprietes-privées.com, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7314</th>\n",
       "      <td>LocalEyes_1</td>\n",
       "      <td>crowdsourced marketing checking (click andwalk...</td>\n",
       "      <td>launch in august 2013. the company provides a ...</td>\n",
       "      <td>[clickandwalk, roamler, bpeekandmobeye.us, qur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7407</th>\n",
       "      <td>Drivoo_1</td>\n",
       "      <td>social network for crowdsourced delivery</td>\n",
       "      <td>prelaunch in france. the company provide a saa...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7550</th>\n",
       "      <td>Braineet_OI_1</td>\n",
       "      <td>open innovation platform between customers and...</td>\n",
       "      <td>lauched in 2014. @101 projets, @microsoft vent...</td>\n",
       "      <td>[eyeka, agorize, betterific, fanvoice, ideascale]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7552</th>\n",
       "      <td>Braineet_OI_2</td>\n",
       "      <td>open innovation platform between customers and...</td>\n",
       "      <td>lauched in 2014. @101 projets, @microsoft vent...</td>\n",
       "      <td>[eyeka, agorize, betterific, fanvoice, ideascale]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7596</th>\n",
       "      <td>Crowdscores_1</td>\n",
       "      <td>crowdsourced sport data</td>\n",
       "      <td>london based founded 2012, they have built a t...</td>\n",
       "      <td>[performgroupplc]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7685</th>\n",
       "      <td>TextMaster _2</td>\n",
       "      <td>marketplace for crowdsourced translation</td>\n",
       "      <td>launched in 10/2011. textmaster is a company t...</td>\n",
       "      <td>[lionbridge, gengo, tolingo, onehourtranslation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7689</th>\n",
       "      <td>woont_1</td>\n",
       "      <td>furniture online shop with a tagging tool</td>\n",
       "      <td>prelaunch in germany (founded in 2010). the co...</td>\n",
       "      <td>[solebich.de, home24.com, fab.com, houzz.com, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7809</th>\n",
       "      <td>Colombio_1</td>\n",
       "      <td>mobile news publishing platform</td>\n",
       "      <td>2 months beta test, full launch planned for oc...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7989</th>\n",
       "      <td>Parko_2</td>\n",
       "      <td>crowdsourcing mobile app to find a parking spot</td>\n",
       "      <td>based in israel, crowdsourced data about peopl...</td>\n",
       "      <td>[streetline]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8162</th>\n",
       "      <td>Yoobic_2</td>\n",
       "      <td>in-store execution mobile solution</td>\n",
       "      <td>yoobic is a crowdsourcing mobile app that allo...</td>\n",
       "      <td>[stayinfront, zenput, traxretail]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8231</th>\n",
       "      <td>IsaHIT_1</td>\n",
       "      <td>impact sourcing platform for digital tasks in ...</td>\n",
       "      <td>founded in 2015, pre-launch\\nisahit is a sourc...</td>\n",
       "      <td>[fiverr, amazonmechanicalturk, clickworker, fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8432</th>\n",
       "      <td>Nimb_1</td>\n",
       "      <td>cowdsource security system</td>\n",
       "      <td>founded in 2014, targets the us market, pre-la...</td>\n",
       "      <td>[roar, revolar, silentbeacon, safelet, wearsafe]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8771</th>\n",
       "      <td>Ornikar_1</td>\n",
       "      <td>online driving license</td>\n",
       "      <td>founded in 2013 in france, ornikar is an onlin...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8801</th>\n",
       "      <td>Ornikar_2</td>\n",
       "      <td>online driving license</td>\n",
       "      <td>founded in 2013 in france, ornikar is an onlin...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8862</th>\n",
       "      <td>Mipise_1</td>\n",
       "      <td>white-label crowdfunding platform</td>\n",
       "      <td>founded in mar 13. mipise enables companies su...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Name  \\\n",
       "1573        Web of Trust _1   \n",
       "2286                Parko_1   \n",
       "2311   Mon Code Juridique_1   \n",
       "2333                Tazza_1   \n",
       "2374            Darjeelin_2   \n",
       "2417        Ideator Crowd_1   \n",
       "2538         Project 1411_1   \n",
       "2743              Geniuzz_1   \n",
       "2769                Mobbr_1   \n",
       "2903            MycrowdQA_1   \n",
       "4293               Mobeye_1   \n",
       "4313          Be-novative_1   \n",
       "4856              BeMyEye_1   \n",
       "4870         CrowdSystems_1   \n",
       "4885            Scoopshot_1   \n",
       "4900                 Qwyk_1   \n",
       "5228           WhereToGet_1   \n",
       "5305           OdinOtvet _1   \n",
       "5489           Sportcloud_1   \n",
       "5620            Tcheck’it_1   \n",
       "5673         welovewords _1   \n",
       "5786               Wezzoo_1   \n",
       "5800              Agorize_1   \n",
       "5813            Recommend_2   \n",
       "6346               Yoobic_1   \n",
       "6381    Front Row Society_1   \n",
       "6494              BeMyEye_2   \n",
       "6553             Evergig _3   \n",
       "6668  Good Morning Design_1   \n",
       "6682            MycrowdQA_2   \n",
       "6717            Testbirds_1   \n",
       "7051             Evergig _2   \n",
       "7095        Foule Factory_1   \n",
       "7300              Immodeo_1   \n",
       "7314            LocalEyes_1   \n",
       "7407               Drivoo_1   \n",
       "7550          Braineet_OI_1   \n",
       "7552          Braineet_OI_2   \n",
       "7596          Crowdscores_1   \n",
       "7685          TextMaster _2   \n",
       "7689                woont_1   \n",
       "7809             Colombio_1   \n",
       "7989                Parko_2   \n",
       "8162               Yoobic_2   \n",
       "8231               IsaHIT_1   \n",
       "8432                 Nimb_1   \n",
       "8771              Ornikar_1   \n",
       "8801              Ornikar_2   \n",
       "8862               Mipise_1   \n",
       "\n",
       "                                                Summary  \\\n",
       "1573                online safety through crowdsourcing   \n",
       "2286    crowdsourcing mobile app to find a parking spot   \n",
       "2311                  cross-platform app for legal code   \n",
       "2333           online search engine of offline products   \n",
       "2374                         crowdsourced travel agency   \n",
       "2417      ideas crowdsourcing platform via gamification   \n",
       "2538                              weather crowdsourcing   \n",
       "2743  crowsourcing marketplace for professional onli...   \n",
       "2769                        crowdsourced labor platform   \n",
       "2903  crowsourcing and freelancing qa plattform (bug...   \n",
       "4293  mobile app that crowdsources local and realtim...   \n",
       "4313  software supporting open enterprise innovation...   \n",
       "4856  mobile app service for crowdsourcing store checks   \n",
       "4870  russian based mobile app service for crowdsour...   \n",
       "4885  crowdsource / competition for pictures/videos ...   \n",
       "4900             crowdsourced same day delivery service   \n",
       "5228                                shazam for shopping   \n",
       "5305  russian crowdsourcing platform for knowledge a...   \n",
       "5489                            performance sharing app   \n",
       "5620                   crowdsourcing marketing checking   \n",
       "5673                  communautary platform for authors   \n",
       "5786  crowdsourced weather service along with social...   \n",
       "5800  crowdsourcing platform for companies competitions   \n",
       "5813        crowdsourcing recommendation social network   \n",
       "6346                           crowdsourced store check   \n",
       "6381                        crowd sourced fashion label   \n",
       "6494    on-demand field audits via mobile crowdsourcing   \n",
       "6553                    crowdsourced video for concert.   \n",
       "6668  marketplace for selling, renting and crowdsour...   \n",
       "6682  crowsourcing and freelancing qa plattform (bug...   \n",
       "6717                               crowdtesting company   \n",
       "7051                    crowdsourced video for concert.   \n",
       "7095  crowdsourcing marketplace specialized in micro...   \n",
       "7300                        automated realestate agency   \n",
       "7314  crowdsourced marketing checking (click andwalk...   \n",
       "7407           social network for crowdsourced delivery   \n",
       "7550  open innovation platform between customers and...   \n",
       "7552  open innovation platform between customers and...   \n",
       "7596                            crowdsourced sport data   \n",
       "7685           marketplace for crowdsourced translation   \n",
       "7689          furniture online shop with a tagging tool   \n",
       "7809                    mobile news publishing platform   \n",
       "7989    crowdsourcing mobile app to find a parking spot   \n",
       "8162                 in-store execution mobile solution   \n",
       "8231  impact sourcing platform for digital tasks in ...   \n",
       "8432                         cowdsource security system   \n",
       "8771                             online driving license   \n",
       "8801                             online driving license   \n",
       "8862                  white-label crowdfunding platform   \n",
       "\n",
       "                                            Description  \\\n",
       "1573  source's name : inventure (slush). founded in ...   \n",
       "2286  based in israel, crowdsourced data about peopl...   \n",
       "2311  founded in 2012 and based in paris, mon code j...   \n",
       "2333  tazza is a search engine of offline products b...   \n",
       "2374  launched a year ago\\nusers can ask to the comm...   \n",
       "2417  founded in turkey in 2013\\nideator crowd is a ...   \n",
       "2538  project 1411 develops a weather crowdsourcing ...   \n",
       "2743  founded in 2011.spain. crowdsourcing marketpla...   \n",
       "2769  2012. delft (netherlands). launch in october 2...   \n",
       "2903  founded in 03/2013 launched in q42014 in the v...   \n",
       "4293  founded in 2013 in france, mobeye is an app th...   \n",
       "4313  hungary based, the company provides a saas pla...   \n",
       "4856  bemyeye can provide images and data from any l...   \n",
       "4870  launched in q4 2012, crowdsystems created an s...   \n",
       "4885  founded in april 2010, scoopshot  is a crowdso...   \n",
       "4900  launch in q3 2013, qwyk develops a crowdsource...   \n",
       "5228  wheretoget is a 'shazam for shopping' : mobile...   \n",
       "5305  combine best features of social network and wi...   \n",
       "5489  prelaunch in france. (prebeta phase) the compa...   \n",
       "5620  launch in 05/2014 in france. there solution is...   \n",
       "5673  crowdsourcing ( brands want brandnames, mottos...   \n",
       "5786  founded in 2012\\n2targets: b2c, b2b (white lab...   \n",
       "5800  founded in 2012 in france, agorize is a platfo...   \n",
       "5813  founded in france 2013\\nrecommend is an online...   \n",
       "6346  yoobic is a crowdsourcing mobile app that allo...   \n",
       "6381  launched in germany. high quality women access...   \n",
       "6494  bemyeye can provide images and data from any l...   \n",
       "6553  founded in 06/2012 in france. the company uses...   \n",
       "6668  3 core activities : selling second-hand furnit...   \n",
       "6682  founded in 03/2013 launched in q42014 in the v...   \n",
       "6717  launched in germany in 2011. uses crowdsourcin...   \n",
       "7051  founded in 06/2012 in france. the company uses...   \n",
       "7095  founded in june 2014. foule factory offers the...   \n",
       "7300  prelaunch in france. immodeo ptop real estate ...   \n",
       "7314  launch in august 2013. the company provides a ...   \n",
       "7407  prelaunch in france. the company provide a saa...   \n",
       "7550  lauched in 2014. @101 projets, @microsoft vent...   \n",
       "7552  lauched in 2014. @101 projets, @microsoft vent...   \n",
       "7596  london based founded 2012, they have built a t...   \n",
       "7685  launched in 10/2011. textmaster is a company t...   \n",
       "7689  prelaunch in germany (founded in 2010). the co...   \n",
       "7809  2 months beta test, full launch planned for oc...   \n",
       "7989  based in israel, crowdsourced data about peopl...   \n",
       "8162  yoobic is a crowdsourcing mobile app that allo...   \n",
       "8231  founded in 2015, pre-launch\\nisahit is a sourc...   \n",
       "8432  founded in 2014, targets the us market, pre-la...   \n",
       "8771  founded in 2013 in france, ornikar is an onlin...   \n",
       "8801  founded in 2013 in france, ornikar is an onlin...   \n",
       "8862  founded in mar 13. mipise enables companies su...   \n",
       "\n",
       "                                            Competitors  \n",
       "1573  [avast, symantec, mcafee, kingsoft, avg, avira...  \n",
       "2286                                                 []  \n",
       "2311                                                 []  \n",
       "2333  [googlemaps, yelps, pinterest, facebook, fours...  \n",
       "2374                                                 []  \n",
       "2417                                           [spigit]  \n",
       "2538                                                 []  \n",
       "2743    [freelancer.com, fiverr, nubelo, twago, bizzby]  \n",
       "2769  [clickworker, crowdflower, odesk, elance, agen...  \n",
       "2903  [applause/utest, usertesting, crowdcurity, bug...  \n",
       "4293  [clickandwalk, bpeekandlocaleyes.us, quri, gig...  \n",
       "4313  [spigit, chaordix, nosco, brigthidea, hype, co...  \n",
       "4856                                                 []  \n",
       "4870      [gigwalk, fieldagent, easyshift, streetspotr]  \n",
       "4885  [cnnireport, celljournalist, geltyimages, flic...  \n",
       "4900  [nodirect, indirect, tiramizoo, shutl, deliv.c...  \n",
       "5228                                                 []  \n",
       "5305                                                 []  \n",
       "5489                                                 []  \n",
       "5620  [localeyesclickandwalk, roamler, bpeekandmobey...  \n",
       "5673                                                 []  \n",
       "5786            [weddar, metwit, skymotion, weathermob]  \n",
       "5800                                                 []  \n",
       "5813  [facebook, foursquaretwitter, pinterest, yelp,...  \n",
       "6346                  [stayinfront, zenput, traxretail]  \n",
       "6381                                                 []  \n",
       "6494  [streetspotr, roamler, appjobber, clicandwalk,...  \n",
       "6553                                             [vevo]  \n",
       "6668                                                 []  \n",
       "6682  [applause/utest, usertesting, crowdcurity, bug...  \n",
       "6717                                                 []  \n",
       "7051                                             [vevo]  \n",
       "7095  [amazonmechanicalturk, crowdflowerclickworker,...  \n",
       "7300  [orpi, fnaim, foncia, proprietes-privées.com, ...  \n",
       "7314  [clickandwalk, roamler, bpeekandmobeye.us, qur...  \n",
       "7407                                                 []  \n",
       "7550  [eyeka, agorize, betterific, fanvoice, ideascale]  \n",
       "7552  [eyeka, agorize, betterific, fanvoice, ideascale]  \n",
       "7596                                  [performgroupplc]  \n",
       "7685   [lionbridge, gengo, tolingo, onehourtranslation]  \n",
       "7689  [solebich.de, home24.com, fab.com, houzz.com, ...  \n",
       "7809                                                 []  \n",
       "7989                                       [streetline]  \n",
       "8162                  [stayinfront, zenput, traxretail]  \n",
       "8231  [fiverr, amazonmechanicalturk, clickworker, fo...  \n",
       "8432   [roar, revolar, silentbeacon, safelet, wearsafe]  \n",
       "8771                                                 []  \n",
       "8801                                                 []  \n",
       "8862                                                 []  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check which opportunities contain certain words in Summary or Description or Market Competitors\n",
    "#################################################################################################################################\n",
    "year_min = 2012\n",
    "list_words_to_find = ['crowd sourc', 'crowdsourc']\n",
    "list_words_to_find_only_in_topics = []\n",
    "list_words_to_avoid = []\n",
    "#################################################################################################################################\n",
    "\n",
    "#Without looking for the words in the 'Business Model / Figures' text\n",
    "sub_df = findwordfrequency_withoutBM(df, topics_df, year_min, list_words_to_find, list_words_to_find_only_in_topics, list_words_to_avoid)\n",
    "\n",
    "#Looking for the words everywhere\n",
    "#sub_df = findwordfrequency_withBM(df, year_min, list_words_to_find, list_words_to_avoid)\n",
    "\n",
    "############## CHECK IF THE SELECTED OPPORTUNITIES MAKE SENSE !!!!! ############################################################\n",
    "print 'Opportunities containing at least one of the word:'\n",
    "sub_df[sub_df.check == 1][['Name', 'Summary', 'Description', 'Competitors']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Export to check precisely\n",
    "sub_df[sub_df.check == 1][['Name', 'Summary', 'Description', 'Competitors']].to_csv('results.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>rowtotal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>99.566161</td>\n",
       "      <td>99.18284</td>\n",
       "      <td>99.072513</td>\n",
       "      <td>98.505338</td>\n",
       "      <td>99.523356</td>\n",
       "      <td>99.115683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.433839</td>\n",
       "      <td>0.81716</td>\n",
       "      <td>0.927487</td>\n",
       "      <td>1.494662</td>\n",
       "      <td>0.476644</td>\n",
       "      <td>0.884317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coltotal</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                2012       2013        2014        2015        2016  \\\n",
       "False      99.566161   99.18284   99.072513   98.505338   99.523356   \n",
       "True        0.433839    0.81716    0.927487    1.494662    0.476644   \n",
       "coltotal  100.000000  100.00000  100.000000  100.000000  100.000000   \n",
       "\n",
       "            rowtotal  \n",
       "False      99.115683  \n",
       "True        0.884317  \n",
       "coltotal  100.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compute percentages per year\n",
    "percentage_table = compute_percentage_per_year(sub_df)\n",
    "percentage_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Export results to csv\n",
    "percentage_table.to_csv('results.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file://C:\\\\Users\\\\vtec-svtec1\\\\Desktop\\\\Dealflow text mining\\\\temp-plot.html'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Plot results in Plotly\n",
    "######################################## CHOOSE YEARS TO KEEP ###################################################################\n",
    "percentage_table = percentage_table[[2012,2013,2014,2015, 2016]]\n",
    "#################################################################################################################################\n",
    "import plotly\n",
    "from plotly.graph_objs import Scatter\n",
    "from plotly.graph_objs import *\n",
    "\n",
    "plotly.offline.plot({\n",
    "    'data': [\n",
    "        Scatter(x=percentage_table.columns,\n",
    "                y=list(percentage_table.ix[1]),\n",
    "                text='',\n",
    "                marker=Marker(),\n",
    "                mode='lines+markers',\n",
    "                line=dict(shape='spline'))\n",
    "    ],\n",
    "    'layout': Layout(xaxis=XAxis(title='Time'), yaxis=YAxis(title='Percentage of yearly dealflow'), \n",
    "                     title = 'Evolution of the percentage of SaaS opportunities')\n",
    "}, show_link=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse competitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vtec-svtec1\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:5: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "C:\\Users\\vtec-svtec1\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\vtec-svtec1\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\vtec-svtec1\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\vtec-svtec1\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\vtec-svtec1\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Competitor</th>\n",
       "      <th>Open_Date</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>006b00000023vCgAAI</td>\n",
       "      <td>youku</td>\n",
       "      <td>2011-02-14</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>006b00000023vCgAAI</td>\n",
       "      <td>netflix</td>\n",
       "      <td>2011-02-14</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>006b00000023vCgAAI</td>\n",
       "      <td>hulu</td>\n",
       "      <td>2011-02-14</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>006b00000023vCiAAI</td>\n",
       "      <td>usbflashdriveswhichutilizesoftwaretoauthentica...</td>\n",
       "      <td>2011-01-17</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>006b00000023vClAAI</td>\n",
       "      <td>-villanao.fr-location-vacances-express.com-res...</td>\n",
       "      <td>2009-05-04</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Id                                         Competitor  \\\n",
       "0  006b00000023vCgAAI                                              youku   \n",
       "1  006b00000023vCgAAI                                            netflix   \n",
       "2  006b00000023vCgAAI                                               hulu   \n",
       "3  006b00000023vCiAAI  usbflashdriveswhichutilizesoftwaretoauthentica...   \n",
       "4  006b00000023vClAAI  -villanao.fr-location-vacances-express.com-res...   \n",
       "\n",
       "    Open_Date  Year  \n",
       "0  2011-02-14  2011  \n",
       "1  2011-02-14  2011  \n",
       "2  2011-02-14  2011  \n",
       "3  2011-01-17  2011  \n",
       "4  2009-05-04  2009  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build a dataframe containing 1 line for each Opportunity/Competitor pair\n",
    "Opp_competitors = build_corresp_table_competitors(df)\n",
    "\n",
    "################################################################################################################################\n",
    "list_wrong_competitors = ['us', 'etc', 'etc.', 'direct', 'indirect', 'traditionalplayers', '...', 'pureplayers', 'france', 'germany']\n",
    "#################################################################################################################################\n",
    "#Remove names identified as \"wrong competitors\"\n",
    "Opp_competitors = remove_wrong_competitors(Opp_competitors, list_wrong_competitors)\n",
    "\n",
    "\n",
    "#################################################################################################################################\n",
    "list_competitors_to_clean = ['facebook', 'google', 'youtube', 'oracle', 'microsoft', 'ibm', 'airbnb', 'groupon', 'linkedin', \n",
    "                             'ebay', 'apple', 'amazon', 'netflix', 'dropbox', 'leboncoin', 'salesforce', 'yelp', 'tripadvisor',\n",
    "                            'uber', 'paypal', 'skype', 'withings', 'meetic', 'tinder', 'foursquare', 'deezer', 'viber','expedia',\n",
    "                            'asos', 'farfetch', 'wix', 'prestashop','sony', 'twitter', 'instagram', 'pinterest', 'adobe', 'whatsapp',\n",
    "                            'snapchat', 'cisco', 'zynga', 'rovio', 'zalando', 'kickstarter', 'slack', 'parrot', 'wordpress','magento',\n",
    "                            'lafourchette', 'pagesjaunes', 'stripe']\n",
    "#################################################################################################################################\n",
    "############# /!\\ ALWAYS CHECK THE RESULT BEFORE ADDING ANY NEW NAME TO THE LIST (Some companies \n",
    "#             have names contained in other well known companies, especially companies with abbreviations in their names) ###########\n",
    "Opp_competitors = clean_main_competitors(Opp_competitors, list_competitors_to_clean)\n",
    "\n",
    "\n",
    "########################################################### CUSTOM CHANGES #########################################################\n",
    "Opp_competitors.Competitor[Opp_competitors.Competitor.apply(lambda X: 'ventepriv' in X)] = 'vente-privee'\n",
    "Opp_competitors.Competitor[Opp_competitors.Competitor.apply(lambda X: 'vente-priv' in X)] = 'vente-privee'\n",
    "Opp_competitors.Competitor[Opp_competitors.Competitor.apply(lambda X: 'vestiaire' in X)] = 'vestiairecollective'\n",
    "Opp_competitors.Competitor[Opp_competitors.Competitor.apply(lambda X: 'windows' in X)] = 'microsoft'\n",
    "Opp_competitors.Competitor[Opp_competitors.Competitor.apply(lambda X: 'itunes' in X)] = 'apple'\n",
    "\n",
    "\n",
    "Opp_competitors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Competitor</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amazon</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>facebook</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ibm</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>microsoft</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>oracle</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>apple</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>linkedin</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>uber</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ebay</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>paypal</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>leboncoin</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sap</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tripadvisor</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>salesforce</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>yelp</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>skype</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>groupon</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>whatsapp</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>criteo</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>dropbox</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>viadeo</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>instagram</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>asos</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>pinterest</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>snapchat</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>withings</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>adobe</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>foursquare</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>ikea</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>hootsuite</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>lafourchette</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>pagesjaunes</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>outfittery</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>advize</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>textmaster</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>yomoni</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>fiverr</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>viewsy</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>thomascook</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>intuit</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>wimdu</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>\\nmarket</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>misterspex</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>weebly</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>walkbase</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>sas</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>alibaba</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>alloresto</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>plyce</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>squarespace</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>mint</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>izettle</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>soundcloud</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>getyourguide</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>zilok</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>zendesk</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>keldoc</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Competitor  Id\n",
       "0          google  76\n",
       "1          amazon  50\n",
       "2        facebook  42\n",
       "3             ibm  38\n",
       "4       microsoft  34\n",
       "5          oracle  33\n",
       "6           apple  33\n",
       "7          airbnb  33\n",
       "8        linkedin  30\n",
       "9            uber  29\n",
       "10           ebay  27\n",
       "11         paypal  25\n",
       "12      leboncoin  23\n",
       "13            sap  22\n",
       "14    tripadvisor  21\n",
       "15     salesforce  19\n",
       "16           yelp  19\n",
       "17          skype  19\n",
       "18        groupon  18\n",
       "19       whatsapp  16\n",
       "20         criteo  16\n",
       "21        dropbox  16\n",
       "22         viadeo  15\n",
       "23      instagram  15\n",
       "24           asos  15\n",
       "25      pinterest  15\n",
       "26       snapchat  14\n",
       "27       withings  13\n",
       "28          adobe  13\n",
       "29     foursquare  13\n",
       "..            ...  ..\n",
       "112          ikea   5\n",
       "113     hootsuite   5\n",
       "114  lafourchette   5\n",
       "115   pagesjaunes   5\n",
       "116    outfittery   5\n",
       "117        advize   5\n",
       "118    textmaster   5\n",
       "119        yomoni   5\n",
       "120        fiverr   5\n",
       "121        viewsy   5\n",
       "122    thomascook   5\n",
       "123        intuit   5\n",
       "124         wimdu   5\n",
       "125      \\nmarket   5\n",
       "126    misterspex   5\n",
       "127        weebly   5\n",
       "128      walkbase   5\n",
       "129           sas   5\n",
       "130       alibaba   5\n",
       "131     alloresto   5\n",
       "132         plyce   5\n",
       "133   squarespace   5\n",
       "134      buzzfeed   5\n",
       "135          mint   5\n",
       "136       izettle   5\n",
       "137    soundcloud   5\n",
       "138  getyourguide   5\n",
       "139         zilok   5\n",
       "140       zendesk   5\n",
       "141        keldoc   5\n",
       "\n",
       "[142 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count mentions of each competitor per year (and the percentage among all mentions per year)\n",
    "count_competitors_date = count_competitors_per_year(Opp_competitors)\n",
    "\n",
    "##########################################################################################################################################\n",
    "year_min = 2013\n",
    "##########################################################################################################################################\n",
    "\n",
    "#Filter by year\n",
    "count_competitors_date = count_competitors_date[count_competitors_date.Year >= year_min]\n",
    "\n",
    "#Check which are the most cited competitors among all opportunities since year_min (See competitors cited more than nb_mentions_min times)\n",
    "nb_mentions_min = 5\n",
    "main_comp_df = pd.DataFrame(count_competitors_date.groupby('Competitor')['Id'].sum()).sort_values(by='Id', ascending = False).reset_index()\n",
    "main_comp_df = main_comp_df[main_comp_df.Id >= nb_mentions_min]\n",
    "#Display the most cited competitors among all opportunities since year_min\n",
    "main_comp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Competitor</th>\n",
       "      <th>Id</th>\n",
       "      <th>pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>tripadvisor</td>\n",
       "      <td>6</td>\n",
       "      <td>0.270758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>yelp</td>\n",
       "      <td>5</td>\n",
       "      <td>0.225632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>booking.com</td>\n",
       "      <td>2</td>\n",
       "      <td>0.090253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>airbnb</td>\n",
       "      <td>8</td>\n",
       "      <td>0.361011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>couchsurfing</td>\n",
       "      <td>2</td>\n",
       "      <td>0.090253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year    Competitor  Id       pct\n",
       "0  2013   tripadvisor   6  0.270758\n",
       "1  2013          yelp   5  0.225632\n",
       "2  2013   booking.com   2  0.090253\n",
       "3  2013        airbnb   8  0.361011\n",
       "4  2013  couchsurfing   2  0.090253"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Choose competitors to display on the graph\n",
    "\n",
    "################################################################################################################################\n",
    "list_competitors_to_display = ['airbnb', 'booking.com', 'tripadvisor', 'yelp', 'expedia', 'couchsurfing']\n",
    "################################################################################################################################\n",
    "\n",
    "count_competitors_date_to_display = count_competitors_date[count_competitors_date.Competitor.isin(list_competitors_to_display)]\n",
    "count_competitors_date_to_display = add_zeros(count_competitors_date_to_display)\n",
    "count_competitors_date_to_display.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Export counts & pct for selected competitors to csv\n",
    "count_competitors_date_to_display.to_csv('results_competitors.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file://C:\\\\Users\\\\vtec-svtec1\\\\Desktop\\\\Dealflow text mining\\\\temp-plot.html'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Plot\n",
    "import plotly\n",
    "from plotly.graph_objs import Scatter\n",
    "from plotly.graph_objs import *\n",
    "\n",
    "plotly.offline.plot({\n",
    "    'data': [\n",
    "        Scatter(x=count_competitors_date_to_display[count_competitors_date_to_display.Competitor == competitor].Year,\n",
    "                y=count_competitors_date_to_display[count_competitors_date_to_display.Competitor == competitor].pct,\n",
    "                text='',\n",
    "                marker=Marker(),\n",
    "                mode='lines+markers',\n",
    "                line=dict(shape='spline'),\n",
    "                name=competitor) for competitor in list_competitors_to_display\n",
    "    ],\n",
    "    'layout': Layout(xaxis=XAxis(title='Time'), yaxis=YAxis(title='Percentage of yearly dealflow'), title = 'Startups main competitors')\n",
    "}, show_link=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
